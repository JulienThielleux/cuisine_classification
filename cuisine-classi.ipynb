{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4526,"databundleVersionId":34463,"sourceType":"competition"}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections import Counter\n\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\n\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nfrom xgboost import XGBClassifier\nimport zipfile\n\n\npd.set_option('display.max_rows', None)\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-16T08:57:41.335668Z","iopub.execute_input":"2023-11-16T08:57:41.336427Z","iopub.status.idle":"2023-11-16T08:57:41.342362Z","shell.execute_reply.started":"2023-11-16T08:57:41.336401Z","shell.execute_reply":"2023-11-16T08:57:41.341783Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Open the files\ntrain_path = '/kaggle/input/whats-cooking/train.json.zip'\nwith zipfile.ZipFile(train_path, 'r') as zip_train:\n    zip_train.extractall()\n\ntest_path = '/kaggle/input/whats-cooking/test.json.zip'\nwith zipfile.ZipFile(test_path, 'r') as zip_test:\n    zip_test.extractall()\n\ntrain_json_path = '/kaggle/working/train.json'\n\ndf_train = pd.read_json(train_json_path)\ntrain = df_train\n\ntest_json_path = '/kaggle/working/test.json'\ndf_test = pd.read_json(test_json_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.344708Z","iopub.execute_input":"2023-11-16T08:57:41.345377Z","iopub.status.idle":"2023-11-16T08:57:41.802885Z","shell.execute_reply.started":"2023-11-16T08:57:41.345332Z","shell.execute_reply":"2023-11-16T08:57:41.802051Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.804348Z","iopub.execute_input":"2023-11-16T08:57:41.804589Z","iopub.status.idle":"2023-11-16T08:57:41.810970Z","shell.execute_reply.started":"2023-11-16T08:57:41.804569Z","shell.execute_reply":"2023-11-16T08:57:41.809958Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((39774, 3), (9944, 2))"},"metadata":{}}]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.811963Z","iopub.execute_input":"2023-11-16T08:57:41.812160Z","iopub.status.idle":"2023-11-16T08:57:41.829016Z","shell.execute_reply.started":"2023-11-16T08:57:41.812142Z","shell.execute_reply":"2023-11-16T08:57:41.828160Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      id      cuisine                                        ingredients\n0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n3  22213       indian                [water, vegetable oil, wheat, salt]\n4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cuisine</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10259</td>\n      <td>greek</td>\n      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25693</td>\n      <td>southern_us</td>\n      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20130</td>\n      <td>filipino</td>\n      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22213</td>\n      <td>indian</td>\n      <td>[water, vegetable oil, wheat, salt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13162</td>\n      <td>indian</td>\n      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.831076Z","iopub.execute_input":"2023-11-16T08:57:41.831352Z","iopub.status.idle":"2023-11-16T08:57:41.839515Z","shell.execute_reply.started":"2023-11-16T08:57:41.831326Z","shell.execute_reply":"2023-11-16T08:57:41.838653Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      id                                        ingredients\n0  18009  [baking powder, eggs, all-purpose flour, raisi...\n1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n2  41580  [sausage links, fennel bulb, fronds, olive oil...\n3  29752  [meat cuts, file powder, smoked sausage, okra,...\n4  35687  [ground black pepper, salt, sausage casings, l...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18009</td>\n      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28583</td>\n      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41580</td>\n      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29752</td>\n      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35687</td>\n      <td>[ground black pepper, salt, sausage casings, l...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.drop(['id'], axis=1, inplace=True)\ntest_id = df_test['id']\ndf_test.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.840244Z","iopub.execute_input":"2023-11-16T08:57:41.840438Z","iopub.status.idle":"2023-11-16T08:57:41.856882Z","shell.execute_reply.started":"2023-11-16T08:57:41.840419Z","shell.execute_reply":"2023-11-16T08:57:41.856065Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.857881Z","iopub.execute_input":"2023-11-16T08:57:41.858403Z","iopub.status.idle":"2023-11-16T08:57:41.882883Z","shell.execute_reply.started":"2023-11-16T08:57:41.858375Z","shell.execute_reply":"2023-11-16T08:57:41.882149Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 39774 entries, 0 to 39773\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   cuisine      39774 non-null  object\n 1   ingredients  39774 non-null  object\ndtypes: object(2)\nmemory usage: 621.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.884024Z","iopub.execute_input":"2023-11-16T08:57:41.884301Z","iopub.status.idle":"2023-11-16T08:57:41.893046Z","shell.execute_reply.started":"2023-11-16T08:57:41.884275Z","shell.execute_reply":"2023-11-16T08:57:41.891975Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9944 entries, 0 to 9943\nData columns (total 1 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   ingredients  9944 non-null   object\ndtypes: object(1)\nmemory usage: 77.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There are no NaN in this dataset","metadata":{}},{"cell_type":"markdown","source":"## We will begin with a brute force approach. Every ingredient of the dataframe will be a feature","metadata":{}},{"cell_type":"code","source":"#Checking every items of the ingredient column.\nexpanded_df = df_train['ingredients'].explode()\ningredient_counts = expanded_df.value_counts()\ningredient_counts_list = ingredient_counts.tolist()\nprint(len(ingredient_counts_list))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.894234Z","iopub.execute_input":"2023-11-16T08:57:41.894521Z","iopub.status.idle":"2023-11-16T08:57:41.962283Z","shell.execute_reply.started":"2023-11-16T08:57:41.894493Z","shell.execute_reply":"2023-11-16T08:57:41.961509Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"6714\n","output_type":"stream"}]},{"cell_type":"code","source":"#This would be way too much features, we will remove each ingredients that appear less than 4 times\nfiltered_ingredient_counts = ingredient_counts[ingredient_counts > 3]\nfiltered_ingredient_list = filtered_ingredient_counts.index.tolist()\nprint(len(filtered_ingredient_list))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.963351Z","iopub.execute_input":"2023-11-16T08:57:41.963593Z","iopub.status.idle":"2023-11-16T08:57:41.967899Z","shell.execute_reply.started":"2023-11-16T08:57:41.963572Z","shell.execute_reply":"2023-11-16T08:57:41.967359Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"3675\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creating a column for each existing ingredient.\nfor ingredient in filtered_ingredient_list:\n    df_train[ingredient.strip().lower()] = False\n\n#Filling those column according to the ingredients column.\nfor index, row in df_train.iterrows():\n    for ingredient in row['ingredients']:\n        ingredient = ingredient.strip().lower()\n        if ingredient in df_train.columns:\n            df_train.at[index, ingredient] = True\n\n#removing the ingredients column.\ndf_train.drop(['ingredients'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:41.969859Z","iopub.execute_input":"2023-11-16T08:57:41.970186Z","iopub.status.idle":"2023-11-16T08:57:56.453640Z","shell.execute_reply.started":"2023-11-16T08:57:41.970166Z","shell.execute_reply":"2023-11-16T08:57:56.452915Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#We split the train dataframe into target and features\nX = df_train.drop('cuisine', axis=1)\ny = df_train['cuisine']","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:56.454569Z","iopub.execute_input":"2023-11-16T08:57:56.454801Z","iopub.status.idle":"2023-11-16T08:57:57.136420Z","shell.execute_reply.started":"2023-11-16T08:57:56.454780Z","shell.execute_reply":"2023-11-16T08:57:57.135632Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Create K-Fold\nkf = KFold(n_splits=5, random_state=0, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:57.137433Z","iopub.execute_input":"2023-11-16T08:57:57.137674Z","iopub.status.idle":"2023-11-16T08:57:57.141173Z","shell.execute_reply.started":"2023-11-16T08:57:57.137654Z","shell.execute_reply":"2023-11-16T08:57:57.140285Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n#We begin with an XGBoost model\nmodel = XGBClassifier(use_label_encoder=False)\n\n#Transform from pandas dataframe to numpy array for XGBoost\nX_array = X.values\ny_array = y.values\n\n#Encode the target to numerical for XGBoost\nle = LabelEncoder()\ny_array = le.fit_transform(y.values)\n\naccuracy_list = []\nfor train_index, valid_index in kf.split(X_array):\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\n    \n    #Train the model\n    model.fit(X_train, y_train, eval_metric='logloss')\n\n    #Make predictions on the validation set\n    y_pred = model.predict(X_valid)\n\n    #Evaluate the model and append the accuracy to the list\n    accuracy = accuracy_score(y_valid, y_pred)\n    accuracy_list.append(accuracy)\n\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:57.142209Z","iopub.execute_input":"2023-11-16T08:57:57.142447Z","iopub.status.idle":"2023-11-16T08:57:57.155707Z","shell.execute_reply.started":"2023-11-16T08:57:57.142425Z","shell.execute_reply":"2023-11-16T08:57:57.154857Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"\\n#We begin with an XGBoost model\\nmodel = XGBClassifier(use_label_encoder=False)\\n\\n#Transform from pandas dataframe to numpy array for XGBoost\\nX_array = X.values\\ny_array = y.values\\n\\n#Encode the target to numerical for XGBoost\\nle = LabelEncoder()\\ny_array = le.fit_transform(y.values)\\n\\naccuracy_list = []\\nfor train_index, valid_index in kf.split(X_array):\\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\\n    \\n    #Train the model\\n    model.fit(X_train, y_train, eval_metric='logloss')\\n\\n    #Make predictions on the validation set\\n    y_pred = model.predict(X_valid)\\n\\n    #Evaluate the model and append the accuracy to the list\\n    accuracy = accuracy_score(y_valid, y_pred)\\n    accuracy_list.append(accuracy)\\n\\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"We get an accuracy of 75% which is not great. For reference this accuracy would put this method in the bottom 33% of this Kaggle competition results.","metadata":{}},{"cell_type":"code","source":"\"\"\"\n#We try a SVM\nmodel = svm.SVC()\n\n#Transform from pandas dataframe to numpy array for SVM\nX_array = X.values\ny_array = y.values\n\n#Encode the target to numerical for SVM\nle = LabelEncoder()\ny_array = le.fit_transform(y.values)\n\naccuracy_list = []\nfor train_index, valid_index in kf.split(X_array):\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\n    \n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions on the validation set\n    y_pred = model.predict(X_valid)\n\n    # Evaluate the model and append the accuracy to the list\n    accuracy = accuracy_score(y_valid, y_pred)\n    accuracy_list.append(accuracy)\n\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get an accuracy of 75% too.","metadata":{}},{"cell_type":"code","source":"#We try a Logistic Regression model\nmodel = LogisticRegression()\n\n#Transform from pandas dataframe to numpy array for Logistic Regression\nX_array = X.values\ny_array = y.values\n\n#Encode the target to numerical for Logistic Regression\nle = LabelEncoder()\ny_array = le.fit_transform(y.values)\n\naccuracy_list = []\nfor train_index, valid_index in kf.split(X_array):\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\n    \n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions on the validation set\n    y_pred = model.predict(X_valid)\n\n    # Evaluate the model and append the accuracy to the list\n    accuracy = accuracy_score(y_valid, y_pred)\n    accuracy_list.append(accuracy)\n\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:57.156792Z","iopub.execute_input":"2023-11-16T08:57:57.157031Z","iopub.status.idle":"2023-11-16T08:57:57.171330Z","shell.execute_reply.started":"2023-11-16T08:57:57.157010Z","shell.execute_reply":"2023-11-16T08:57:57.170448Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"\\n#We try a Logistic Regression model\\nmodel = LogisticRegression()\\n\\n#Transform from pandas dataframe to numpy array for Logistic Regression\\nX_array = X.values\\ny_array = y.values\\n\\n#Encode the target to numerical for Logistic Regression\\nle = LabelEncoder()\\ny_array = le.fit_transform(y.values)\\n\\naccuracy_list = []\\nfor train_index, valid_index in kf.split(X_array):\\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\\n    \\n    # Train the model\\n    model.fit(X_train, y_train)\\n\\n    # Make predictions on the validation set\\n    y_pred = model.predict(X_valid)\\n\\n    # Evaluate the model and append the accuracy to the list\\n    accuracy = accuracy_score(y_valid, y_pred)\\n    accuracy_list.append(accuracy)\\n\\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"We get an accuracy of 77.6% which is better and rank us in the top 50% of this Kaggle competition results.","metadata":{}},{"cell_type":"code","source":"#We try a SVM\nmodel = svm.SVC()\n\n#Transform from pandas dataframe to numpy array for SVM\nX_array = X.values\ny_array = y.values\n\n#Encode the target to numerical for SVM\nle = LabelEncoder()\ny_array = le.fit_transform(y.values)\n\naccuracy_list = []\nfor train_index, valid_index in kf.split(X_array):\n    X_train, X_valid = X_array[train_index], X_array[valid_index]\n    y_train, y_valid = y_array[train_index], y_array[valid_index]\n    \n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions on the validation set\n    y_pred = model.predict(X_valid)\n\n    # Evaluate the model and append the accuracy to the list\n    accuracy = accuracy_score(y_valid, y_pred)\n    accuracy_list.append(accuracy)\n\nprint(f'Mean Accuracy: {np.mean(accuracy_list)}')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:57:57.172399Z","iopub.execute_input":"2023-11-16T08:57:57.172641Z","iopub.status.idle":"2023-11-16T11:35:20.167132Z","shell.execute_reply.started":"2023-11-16T08:57:57.172619Z","shell.execute_reply":"2023-11-16T11:35:20.166235Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Mean Accuracy: 0.7593400171665897\n","output_type":"stream"}]},{"cell_type":"code","source":"#We process the test dataframe in the same way as the training dataframe.\n\nfor ingredient in filtered_ingredient_list:\n    df_test[ingredient.strip().lower()] = False\n\n\nfor index, row in df_test.iterrows():\n    for ingredient in row['ingredients']:\n        ingredient = ingredient.strip().lower()\n        if ingredient in df_test.columns:\n            df_test.at[index, ingredient] = True\n\ndf_test.drop(['ingredients'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:35:20.168459Z","iopub.execute_input":"2023-11-16T11:35:20.168993Z","iopub.status.idle":"2023-11-16T11:35:27.112394Z","shell.execute_reply.started":"2023-11-16T11:35:20.168962Z","shell.execute_reply":"2023-11-16T11:35:27.111776Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Make predictions on the new data\n\nX_test = df_test.values\ny_test = model.predict(X_test)\n#prediction_df = pd.DataFrame(y_test, columns=['cuisine'])\n\nprediction_np = le.inverse_transform(y_test)\nprediction_df = pd.DataFrame(prediction_np)\n\n#Add back the index column\nprediction_df = pd.concat([test_id,prediction_df],axis=1)\nprediction_df.columns = ['id','cuisine']\n\nprediction_df.to_csv('submission.csv', header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T11:35:27.113431Z","iopub.execute_input":"2023-11-16T11:35:27.113862Z","iopub.status.idle":"2023-11-16T11:43:45.185043Z","shell.execute_reply.started":"2023-11-16T11:35:27.113828Z","shell.execute_reply":"2023-11-16T11:43:45.184288Z"},"trusted":true},"execution_count":19,"outputs":[]}]}